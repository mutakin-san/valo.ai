{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULeJC3CGBG7Z"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q scann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ0FnBp8B5aD"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pathlib\n",
        "from google.colab import files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxgy1NSpzu2S"
      },
      "outputs": [],
      "source": [
        "users = pd.read_csv('https://raw.githubusercontent.com/mutakin-san/valo.ai/main/machine-learning/dataset/user_valo_mod_str.csv')\n",
        "users.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhOhOCMU7rq4"
      },
      "outputs": [],
      "source": [
        "grouped_data_dict = users.groupby(['user_id', 'vac_booster'])['vac_1', 'vac_2'].sum().reset_index()\n",
        "\n",
        "grouped_data_dict = {name: np.array(value) for name, value in grouped_data_dict.items()}\n",
        "grouped_data = tf.data.Dataset.from_tensor_slices(grouped_data_dict)\n",
        "\n",
        "booster_dict = users[['vac_booster']].drop_duplicates()\n",
        "booster_dict = {name: np.array(value) for name, value in booster_dict.items()}\n",
        "booster = tf.data.Dataset.from_tensor_slices(booster_dict)\n",
        "\n",
        "grouped_data = grouped_data.map(lambda x: {\n",
        "    'user_id' : str(x['user_id']), \n",
        "    'vac_booster' : x['vac_booster'], \n",
        "    'vac_1' : x['vac_1'],\n",
        "    'vac_2' : x['vac_2'],\n",
        "\n",
        "})\n",
        "\n",
        "booster = booster.map(lambda x: x['vac_booster'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM-obuaeYVdw"
      },
      "outputs": [],
      "source": [
        "booster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnNXEXR1pbgy"
      },
      "outputs": [],
      "source": [
        "unique_boosters = np.unique(np.concatenate(list(booster.batch(1000))))\n",
        "unique_user_ids = np.unique(np.concatenate(list(grouped_data.batch(1_000).map(lambda x: x[\"user_id\"]))))\n",
        "print(unique_boosters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bEPY1sZiEX_"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = grouped_data.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(60_000)\n",
        "test = shuffled.skip(60_000).take(40_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEVqKDxeijp8"
      },
      "outputs": [],
      "source": [
        "class VaccineModel(tfrs.Model):\n",
        "  def __init__(self, user_model, booster_model):\n",
        "    super().__init__()\n",
        "    booster_model = tf.keras.Sequential([\n",
        "                                      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "                                          vocabulary=unique_boosters, mask_token=None),\n",
        "                                      tf.keras.layers.Embedding(len(unique_boosters) + 1, embedding_dimension)\n",
        "    ])\n",
        "    self.booster_model: tf.keras.Model = booster_model\n",
        "\n",
        "    user_model = tf.keras.Sequential([\n",
        "                                      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "                                          vocabulary=unique_user_ids, mask_token=None),\n",
        "                                      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "    ])\n",
        "    self.user_model: tf.keras.Model = user_model\n",
        "\n",
        "    metrics = tfrs.metrics.FactorizedTopK(\n",
        "      candidates=booster.batch(512).map(booster_model)\n",
        "    )\n",
        "\n",
        "    task = tfrs.tasks.Retrieval(metrics=metrics)\n",
        "    self.task: tf.keras.layers.Layer = task\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    user_embeddings = self.user_model(features['user_id'])\n",
        "    positive_vac_embeddings = self.booster_model(features['vac_booster'])\n",
        "    return self.task(user_embeddings, positive_vac_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa1uBRz_w5aC"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 32\n",
        "\n",
        "booster_model = tf.keras.Sequential([\n",
        "                                  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "                                      vocabulary=unique_boosters, mask_token=None),\n",
        "                                  tf.keras.layers.Embedding(len(unique_boosters) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "user_model = tf.keras.Sequential([\n",
        "                                  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "                                      vocabulary=unique_user_ids, mask_token=None),\n",
        "                                  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "model = VaccineModel(user_model, booster_model)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01))\n",
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()\n",
        "\n",
        "history = model.fit(cached_train, epochs=2)\n",
        "model.evaluate(cached_test, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZelzYcunz7OP"
      },
      "outputs": [],
      "source": [
        "epochs = [i for i in range(2)]\n",
        "\n",
        "plt.plot(epochs, history.history[\"factorized_top_k/top_5_categorical_accuracy\"], label=\"accuracy\")\n",
        "plt.title(\"Accuracy vs epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Top-100 accuracy\");\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FSr6qdK0OkP"
      },
      "outputs": [],
      "source": [
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model, k=2)\n",
        "index.index_from_dataset(\n",
        "    booster.batch(128).map(lambda title: (title, model.booster_model(title)))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubkZwUYC7hYY"
      },
      "outputs": [],
      "source": [
        "_, vac = index(tf.constant([\"42\"]))\n",
        "print(f\"Recommendations for user 42: {vac[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg8XTguPzdeI"
      },
      "outputs": [],
      "source": [
        "# Export the query model.\n",
        "with tempfile.TemporaryDirectory() as tmp:\n",
        "  path = os.path.join(tmp, \"model\")\n",
        "\n",
        "  # Save the index.\n",
        "  tf.saved_model.save(index, path)\n",
        "\n",
        "  # Load it back; can also be done in TensorFlow Serving.\n",
        "  loaded = tf.saved_model.load(path)\n",
        "\n",
        "  # Pass a user id in, get top predicted vaccines\n",
        "  scores, vaccines = loaded([\"42\"])\n",
        "\n",
        "  print(f\"Recommendations: {vaccines[0][:3]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18X_9SSSuMZI"
      },
      "outputs": [],
      "source": [
        "#Convert to saved_model.pb\n",
        "export_dir = '/tmp/tmpq97dd3hj/model'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "#Convert to TFLITE\n",
        "tflite_model_file = pathlib.Path('/tmp/vac.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lAGb-TCzz3Ct"
      },
      "outputs": [],
      "source": [
        "#download tflite files\n",
        "#uncomment below for need\n",
        "# files.download(tflite_model_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tfrs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
