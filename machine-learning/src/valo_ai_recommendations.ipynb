{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULeJC3CGBG7Z"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q scann\n",
        "!pip install tflite-support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ0FnBp8B5aD"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pathlib\n",
        "from google.colab import files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxgy1NSpzu2S"
      },
      "outputs": [],
      "source": [
        "users = pd.read_csv('https://raw.githubusercontent.com/mutakin-san/valo.ai/main/machine-learning/dataset/user_valo_mod_str.csv')\n",
        "users.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = users.shape\n",
        "shape"
      ],
      "metadata": {
        "id": "sJJvQQH4j4h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhOhOCMU7rq4"
      },
      "outputs": [],
      "source": [
        "grouped_data_dict = users.groupby(['user_id', 'vac_booster'])['vac_1', 'vac_2'].sum().reset_index()\n",
        "\n",
        "grouped_data_dict = {name: np.array(value) for name, value in grouped_data_dict.items()}\n",
        "grouped_data = tf.data.Dataset.from_tensor_slices(grouped_data_dict)\n",
        "\n",
        "booster_dict = users[['vac_booster']].drop_duplicates()\n",
        "booster_dict = {name: np.array(value) for name, value in booster_dict.items()}\n",
        "booster = tf.data.Dataset.from_tensor_slices(booster_dict)\n",
        "\n",
        "grouped_data = grouped_data.map(lambda x: {\n",
        "    'user_id' : str(x['user_id']), \n",
        "    'vac_booster' : x['vac_booster'], \n",
        "    'vac_1' : x['vac_1'],\n",
        "    'vac_2' : x['vac_2'],\n",
        "\n",
        "})\n",
        "\n",
        "booster = booster.map(lambda x: x['vac_booster'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = list(grouped_data)\n",
        "l[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeETqDU9iSIh",
        "outputId": "57595ca8-7156-4782-9dbd-ced274098254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'Tensor(\"args_0:0\", shape=(), dtype=int64)'>,\n",
              " 'vac_1': <tf.Tensor: shape=(), dtype=string, numpy=b'Sinopharm'>,\n",
              " 'vac_2': <tf.Tensor: shape=(), dtype=string, numpy=b'Sinopharm'>,\n",
              " 'vac_booster': <tf.Tensor: shape=(), dtype=string, numpy=b'Janssen'>}"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM-obuaeYVdw"
      },
      "outputs": [],
      "source": [
        "booster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnNXEXR1pbgy"
      },
      "outputs": [],
      "source": [
        "unique_boosters = np.unique(np.concatenate(list(booster.batch(1000))))\n",
        "unique_user_ids = np.unique(np.concatenate(list(grouped_data.batch(1_000).map(lambda x: x[\"vac_1\"]))))\n",
        "unique_user_ids2 = np.unique(np.concatenate(list(grouped_data.batch(1_000).map(lambda x: x[\"vac_2\"]))))\n",
        "print(unique_boosters)\n",
        "print(unique_user_ids)\n",
        "print(unique_user_ids2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bEPY1sZiEX_"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = grouped_data.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(60_000)\n",
        "test = shuffled.skip(60_000).take(40_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEVqKDxeijp8"
      },
      "outputs": [],
      "source": [
        "class VaccineModel(tfrs.Model):\n",
        "  def __init__(self, user_model, booster_model):\n",
        "    super().__init__()\n",
        "    booster_model = tf.keras.Sequential([\n",
        "                                      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "                                          vocabulary=unique_boosters, mask_token=None),\n",
        "                                      tf.keras.layers.Embedding(len(unique_boosters) + 1, embedding_dimension)\n",
        "    ])\n",
        "    self.booster_model: tf.keras.Model = booster_model\n",
        "\n",
        "    user_model = tf.keras.Sequential([\n",
        "                                      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "                                          vocabulary=unique_user_ids, mask_token=None),\n",
        "                                      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "    ])\n",
        "    self.user_model: tf.keras.Model = user_model\n",
        "\n",
        "    metrics = tfrs.metrics.FactorizedTopK(\n",
        "      candidates=booster.batch(512).map(booster_model)\n",
        "    )\n",
        "\n",
        "    task = tfrs.tasks.Retrieval(metrics=metrics)\n",
        "    self.task: tf.keras.layers.Layer = task\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    user_embeddings = self.user_model(features['vac_1'], features['vac_2'])\n",
        "    positive_vac_embeddings = self.booster_model(features['vac_booster'])\n",
        "    return self.task(user_embeddings, positive_vac_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa1uBRz_w5aC"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 32\n",
        "\n",
        "booster_model = tf.keras.Sequential([\n",
        "                                  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "                                      vocabulary=unique_boosters, mask_token=None),\n",
        "                                  tf.keras.layers.Embedding(len(unique_boosters) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "user_model = tf.keras.Sequential([\n",
        "                                  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "                                      vocabulary=unique_user_ids, mask_token=None),\n",
        "                                  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "model = VaccineModel(user_model, booster_model)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01))\n",
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()\n",
        "\n",
        "history = model.fit(cached_train, epochs=10)\n",
        "model.evaluate(cached_test, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZelzYcunz7OP"
      },
      "outputs": [],
      "source": [
        "epochs = [i for i in range(10)]\n",
        "\n",
        "plt.plot(epochs, history.history[\"factorized_top_k/top_5_categorical_accuracy\"], label=\"accuracy\")\n",
        "plt.title(\"Accuracy vs epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Top-100 accuracy\");\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FSr6qdK0OkP"
      },
      "outputs": [],
      "source": [
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model, k=3)\n",
        "index.index_from_dataset(\n",
        "    booster.batch(128).map(lambda title: (title, model.booster_model(title)))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubkZwUYC7hYY"
      },
      "outputs": [],
      "source": [
        "_, vac = index(tf.constant([\"Moderna\", \"Moderna\"]))\n",
        "print(f\"Recommendations for user 42: {vac[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(index, \"export\")"
      ],
      "metadata": {
        "id": "ex57nDIyYFlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load it back; can also be done in TensorFlow Serving.\n",
        "loaded = tf.saved_model.load(\"export\")\n",
        "\n",
        "# Pass a user id in, get top predicted vaccines\n",
        "scores, vaccines = loaded([\"AZ\", \"AZ\"])\n",
        "\n",
        "print(f\"Recommendations: {vaccines[0]}\")"
      ],
      "metadata": {
        "id": "KbaI-UjeYW7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loaded.signatures['serving_default'].inputs)"
      ],
      "metadata": {
        "id": "47ozdOT5spMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Recommendations: {scores[0]}\")"
      ],
      "metadata": {
        "id": "JhW7IssPA_eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"export\")\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "id": "VWiE0t3bYgBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(input_details)\n",
        "\n",
        "# test the model\n",
        "input_shape = input_details[0]['shape']\n",
        "print(input_shape)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array([\"Janssen\"]))\n",
        "# interpreter.set_tensor(input_details[0]['index'], np.array([\"Pfizer\"]))\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "output_data = interpreter.get_tensor(output_details[1]['index'])\n",
        "print(output_data[0])"
      ],
      "metadata": {
        "id": "otU2sOiDg_kt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "valo-ai-recommendations.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}